# -*- coding: utf-8 -*-
"""Heart Attack Analysis & Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GCrsbJoWTNhWkFuSdL5v6U9CDJhv7WON

## Import All Package Dependencies
"""

pip install yellowbrick

# Commented out IPython magic to ensure Python compatibility.
# Initial processing and visualization related
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
import missingno as msn
import plotly.express as px
from yellowbrick.classifier import ClassPredictionError

# Data processing and transforming
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import AdaBoostRegressor
from sklearn.preprocessing import LabelEncoder

# Model development related
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV

#Model evaluation related
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, ConfusionMatrixDisplay, f1_score, recall_score
from sklearn.model_selection import cross_validate

# Colab-related/file management
from google.colab import drive
from google.colab import files
import os, zipfile, shutil

"""## Data Loading"""

# Mount google drive
drive.mount('/content/drive/')

# Read dataset
heart = pd.read_csv('/content/drive/MyDrive/Datasets/heart.csv')
heart.head()

"""## Exploratory Data Analysis

Check dataset basic info
"""

heart.info()

"""Describe statistics of dataset"""

heart.describe().T

"""From the table above we can see that cholesterol and restingBP which are a numerical feature have min value of 0.  Meanwhile resting blood pressure are measured in [mm Hg] while cholesterol are measured [mm/dl] so there is no way their value can be 0.  So we must handle these missing value."""

# Check sum of missing value

rbp = (heart.RestingBP == 0).sum()
cho = (heart.Cholesterol == 0).sum()

print('Value 0 in RestingBP column: ', rbp)
print('Value 0 in Cholesterol column: ', cho)

heart.loc[(heart['RestingBP']==0)]

"""There is only 1 missing value on RestingBP column so we can just drop it, but there is so much missing value on Cholesterol column while the count of dataset itself is not that much (less than 1000) so every data count and we can fill the missing value using mean from all data."""

# Drop missing value in RestingBP row
heart = heart.loc[(heart[['RestingBP']]!=0).all(axis=1)]
heart.shape

# Fill missing value in Cholesterol column with mean
heart['Cholesterol'].replace(0, heart['Cholesterol'].mean(axis=0), inplace=True)

# Recheck if the 0 value have been handled
cho2 = (heart.Cholesterol == 0).sum()
print('Value 0 in Cholesterol column: ', cho2)

"""## Handle Outliers
Detect outliers in some of the numerical feature such as resting bp, cholesterol, max HR, and old peak using boxplot
"""

# Age Feature
sns.boxplot(x=heart['Age'])

# Resting Blood Pressure Feature
sns.boxplot(x=heart['RestingBP'])

# Cholesterol Feature
sns.boxplot(x=heart['Cholesterol'])

# Maximum Heart Rate Achieved Feature
sns.boxplot(x=heart['MaxHR'])

# Oldpeak Feature
sns.boxplot(x=heart['Oldpeak'])

"""Use IQR Method to remove the outliers"""

Q1 = heart.quantile(0.25)
Q3 = heart.quantile(0.75)


IQR=Q3-Q1
heart=heart[~((heart<(Q1-1.5*IQR))|(heart>(Q3+1.5*IQR))).any(axis=1)]

# Check dataset size after drop outliers
heart.shape

"""## Univariate Analysis
We do univariate analysis to each variable as their own data

The Attributess include:
- Age: age of the patient [years]
- Sex: sex of the patient [M: Male, F: Female]
- ChestPainType: chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]
- RestingBP: resting blood pressure [mm Hg]
- Cholesterol: serum cholesterol [mm/dl]
- FastingBS: fasting blood sugar [1: if FastingBS > 120 mg/dl, 0: otherwise]
- RestingECG: resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]
- MaxHR: maximum heart rate achieved [Numeric value between 60 and 202]
ExerciseAngina: exercise-induced angina [Y: Yes, N: No]
Oldpeak: oldpeak = ST [Numeric value measured in depression]
- ST_Slope: the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]
- HeartDisease: output class [1: heart disease, 0: Normal]

Split categorical features and numerical features so we can analyze them with univariate method
"""

categorical_features = ['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']
numerical_features = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']

"""### Categorical Exploratory"""

# Define functions to analyze categorical data
def analysis_categorical(categorical_features):
  feature = categorical_features
  count = heart[feature].value_counts()
  percent = 100*heart[feature].value_counts(normalize=True)
  df = pd.DataFrame({'Sample count':count, 'percentage':percent.round(1)})
  print(df)
  count.plot(kind='bar', title=feature)

# Sex Features
analysis_categorical(categorical_features[0])

"""From the graphic above we can see that this feature is pretty imbalanced because 76.9% of the dataset are categorized as Male and may make the models biased."""

# Chest Pain Type
analysis_categorical(categorical_features[1])

"""The chest pain type are classified as follow: [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]

And from the graphic above we can conclude that many of the sample in the dataset dont have a symptoms.
"""

# Fasting Blood Sugar
analysis_categorical(categorical_features[2])

"""The fasting Blood sugar are supposed to be a categorical feature which composed of 1 if FastingBS > 120mg/dl, and 0 if otherwise.  But it seems all of the data for 1 is being cleaned and only data of FastingBS < 120mg/dl remains.  So this is just a one-sided data and pretty much imbalanced.  So we can drop this column"""

# Drop FastingBS Column

del heart['FastingBS']
heart

# Resting Electrocargiogram Result
analysis_categorical(categorical_features[3])

"""The resting electrocardiogram result are classified as follow: [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]

And from the graphic above we can see that most of the samples have normal result
"""

# Exercise Included Angina
analysis_categorical(categorical_features[4])

"""From the graphic above we can see that there are more samples that dont have included angina on exercise."""

# Exercise ST Slope
analysis_categorical(categorical_features[5])

"""The ST Slope feature means the slope of the peak exercise ST segment and classified as follow: [Up: upsloping, Flat: flat, Down: downsloping]

And from the graphic above we can see that the samples are balance on the upsloping and flat while there is a few samples which are downsloping

### Numerical Exploratory
"""

# See histogram of each numerical feature
heart.hist(bins=50, figsize=(30, 20))
plt.show()

"""From the histogram above we can get some information such as:
1. Many of the age demography are between 40-60 and reach it peaks around 55.
2. The number between sample who get heart disease and not are approximately equal which means the label are balance
3. Most of the sample have 0 value in oldpeak feature which mean it doesnt really related to depression, because this feature is a measurement for depression
4. Many of the serum cholesterol sample are above 200mm/dl while according to some article the ideal serum cholesterol are below 200mm/dl

### Check linearity of variable to look for skewness of overall features
"""

plt.figure(figsize=(15,10))
for i,col in enumerate(heart.columns,1):
    plt.subplot(4,3,i)
    plt.title(f"Distribution of {col} Data")
    sns.histplot(heart[col],kde=True)
    plt.tight_layout()
    plt.plot()

"""## Multivariate Analysis
We do multivariate analysis to know the relation between 2 or more variable

### Categorical Feature Exploratory
"""

# See distribution of categorical column to heart disease
cat_features = heart.select_dtypes(include='object').columns.to_list()

for col in cat_features:
  fig=px.histogram(heart, 
                 x="HeartDisease",
                 color=col,
                 hover_data=heart.columns,
                 title="Distribution of Heart Diseases to - {}".format(col),
                 barmode="group", 
                 text_auto=True)
  fig.show()

"""From these graphs plot we get some insight such as:
1. There are large margin ration between male to female who got heart diseases.So we can conclude male are more prone to heart diseases than female.
2. Most of people who got heart diseases dont have a symptomps.
3. Most of people who got heart diseases have normal resting ECG result, but many people who also got normal resting ECG result also dont have a heart diseases.  We can conclude this feature doesn't realy contribute much to heart diseases.
4. People who have exercise-included angina are more prone to heart diseases.
5. Most of people who got heart disease have flat st segment result.
6. From above insights we can see a certain pattern for people who got heart diseases and feature that dont really contribute to hert diseases.

Based on the conclusion above we can drop the resting ecg column
"""

# Drop resting ecg column
del heart['RestingECG']
heart.head()

"""### Numerical Feature Exploratory"""

# Use pair plot to analyze relation between numeric feature
sns.pairplot(heart, diag_kind = 'kde', hue='HeartDisease')

"""### See Correlation Matrix"""

plt.figure(figsize=(15, 12))
correlation_matrix = heart.corr().round(2)

# To print the value inside the box we set the param annot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidth=0.5, )
plt.title("Correlation matrix for numeric feature", size=20)

"""From the correlation matrix above we can see that serum cholesterol has very little correlation value to heart disease (near 0) so we can drop it.  And we can see that MaxHR has a high negative correlation with heart diseases."""

# Drop the cholesterol column
# heart.drop(['Cholesterol'], inplace=True, axis=1)

# See data after EDA
# heart.head()

"""## Data Preparation

### Handling Categorical Features
We will use label encoding to handle the categorical features
"""

# Turn categorical column into string
string_col = heart.select_dtypes(include="object").columns
heart[string_col]=heart[string_col].astype("string")

# Get categorical column
string_col=heart.select_dtypes("string").columns.to_list()

# Check data types of dataset
heart.dtypes

# See the distribution of categorical column
heart[string_col].head()
for col in string_col:
    print(f"The distribution of categorical valeus in the {col} is : ")
    print(heart[col].value_counts())

# Apply label incoding into dataset
new_df = heart.apply(LabelEncoder().fit_transform)

new_df.head()

"""### Train Test Split
Split train and test into 80 : 20
"""

X = new_df.drop(['HeartDisease'], axis=1)
y = new_df['HeartDisease']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

# See data train
X_train.sample()

# Check each sample of splitted data
print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""### Standardization"""

numerical_features = ['Age', 'RestingBP', 'MaxHR', 'Oldpeak']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

# Check data after standardization
X_train[numerical_features].describe().round(4)

"""## Base Model Development

We will try to use tree based model in order to solve this classification problem such as decision tree, random forest, and XG Boost

## Decision Tree

### Modelling Base Decision Tree
"""

DT = DecisionTreeClassifier(class_weight="balanced", criterion="entropy", random_state=101)
DT.fit(X_train, y_train)
y_pred = DT.predict(X_test)

"""### Model Evaluation for DT"""

# First we need to scale data test
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

# Def function for model evaluation
def evaluate(y_test, y_pred):
  print(classification_report(y_test, y_pred))
  acc=accuracy_score(y_test, y_pred)
  print(acc)
  print('\nConfusion matrix: \n', confusion_matrix(y_test, y_pred))
  ConfusionMatrixDisplay.from_predictions(y_test, y_pred)

# Model Evaluation
evaluate(y_test, y_pred)

# See class prediction error
visualizer = ClassPredictionError(DT)
visualizer.fit(X_train, y_train)
visualizer.score(X_test, y_test)
visualizer.poof()

# Cross-Validating Decision Tree (DT)
dt_xvalid_model = DecisionTreeClassifier(max_depth=None, random_state=101)

dt_xvalid_model_scores = cross_validate(dt_xvalid_model, X_train, y_train, scoring = ["accuracy", "recall"], cv = 10)
dt_xvalid_model_scores = pd.DataFrame(dt_xvalid_model_scores, index = range(1, 11))

dt_xvalid_model_scores

# See average validation score
dt_xvalid_model_scores.mean()

"""### Modelling Decision Tree Using Grid Search"""

# Define parameter grid
param_grid = {"criterion":["gini", "entropy"],
              "splitter":["best", "random"],
              "max_depth": [None, 3, 6, 9, 12],
              "max_features":[None, 3, 5, 7],
              "min_samples_leaf": [2, 3, 4],
              "min_samples_split": [2, 3, 5, 7, 9, 12]}

# Iniate new model for grid search
DT_grid = DecisionTreeClassifier(class_weight = "balanced", random_state=101)
DT_grid = GridSearchCV(estimator=DT_grid,
                            param_grid=param_grid,
                            scoring='recall',
                            n_jobs = -1,
                            verbose = 2).fit(X_train, y_train)

# Evaluate model after grid search
y_pred = DT_grid.best_estimator_.predict(X_test)
evaluate(y_test, y_pred)

# Save score for later comparison
dt_grid_acc = accuracy_score(y_test, y_pred)
dt_grid_recall = recall_score(y_test, y_pred)

"""### Feature Importance for Decision Tree Model"""

DT_grid.best_estimator_.feature_importances_

# Define df for feature importances
DT_feature_imp = pd.DataFrame(index=X.columns, data = DT_grid.best_estimator_.feature_importances_,
                      columns = ["Feature Importance"]).sort_values("Feature Importance")
DT_feature_imp

# Plot feature importances
sns.barplot(x=DT_feature_imp["Feature Importance"], y=DT_feature_imp.index)
plt.title("Feature Importance")
plt.show()

"""## Random Forest

### Modelling Base Random Forest
"""

RF = RandomForestClassifier(class_weight="balanced", criterion='entropy', random_state=101)
RF.fit(X_train, y_train)
y_pred = RF.predict(X_test)

"""### Model Evaluation for RF

"""

# Model Evaluation
evaluate(y_test, y_pred)

# See class prediction error
visualizer = ClassPredictionError(RF)
visualizer.fit(X_train, y_train)
visualizer.score(X_test, y_test)
visualizer.poof()

# Cross-Validating Random Forest (RF)
rf_xvalid_model = RandomForestClassifier(max_depth=None, random_state=101)

rf_xvalid_model_scores = cross_validate(rf_xvalid_model, X_train, y_train, scoring = ["accuracy", "recall"], cv = 10)
rf_xvalid_model_scores = pd.DataFrame(rf_xvalid_model_scores, index = range(1, 11))

rf_xvalid_model_scores

# See average validation score
rf_xvalid_model_scores.mean()

"""### Modelling Random Forest Using Grid Search"""

# Define param grid
param_grid = {'criterion':['gini', 'entropy'],
             'n_estimators':[100, 200, 300],
             'max_features':[3, 4, 5],
             'max_depth':[3, 5, 7, 9],
             'min_samples_split':[2, 5, 8]}

# Iniate new model for grid search
RF_grid = RandomForestClassifier(class_weight="balanced", random_state=101)

RF_grid = GridSearchCV(estimator=RF_grid, 
                       param_grid=param_grid, 
                       scoring = "recall", 
                       n_jobs = -1, 
                       verbose = 2).fit(X_train, y_train)

# Evaluate model after grid search
y_pred = RF_grid.best_estimator_.predict(X_test)
evaluate(y_test, y_pred)

# Save score for later comparison
rf_grid_acc = accuracy_score(y_test, y_pred)
rf_grid_recall = recall_score(y_test, y_pred)

"""### Feature Importance for Random Forest Model"""

RF_grid.best_estimator_.feature_importances_

# Define RF feature importances
RF_feature_imp = pd.DataFrame(index = X.columns, data = RF_grid.best_estimator_.feature_importances_,
                              columns = ["Feature Importance"]).sort_values("Feature Importance", ascending = False)
RF_feature_imp

# Plot feature importances
sns.barplot(x=RF_feature_imp["Feature Importance"], y=RF_feature_imp.index)
plt.title("Feature Importance")
plt.show()

"""Compare the feature importance result with the decision tree one"""

sns.barplot(x=DT_feature_imp["Feature Importance"], y=DT_feature_imp.index)
plt.title("Feature Importance")
plt.show()

"""## XGBoost

### Modelling base XGBoost
"""

XGB = XGBClassifier(random_state=101)
XGB.fit(X_train, y_train)
y_pred = XGB.predict(X_test)

"""### Model Evaluation for XGBoost"""

# Model Evaluation
evaluate(y_test, y_pred)

# See class prediction error
visualizer = ClassPredictionError(XGB)
visualizer.fit(X_train, y_train)
visualizer.score(X_test, y_test)
visualizer.poof()

# Cross-Validating XGBoost
xgb_xvalid_model = XGBClassifier(random_state=101)

xgb_xvalid_model_scores = cross_validate(xgb_xvalid_model, X_train, y_train, scoring = ["accuracy", "recall"], cv = 10)
xgb_xvalid_model_scores = pd.DataFrame(xgb_xvalid_model_scores, index = range(1, 11))

xgb_xvalid_model_scores

# See cv avg score
xgb_xvalid_model_scores.mean()

"""### Modelling XGBoost Using Grid Search"""

param_grid = {"n_estimators":[100, 200, 300], 
              "max_depth":[3,5,6,7,8], 
              "learning_rate": [0.01, 0.03, 0.1, 0.3],
              "subsample":[0.5, 1], 
              "colsample_bytree":[0.5, 1]}

# Initiate new xgb model for grid search
XGB_grid = XGBClassifier(random_state=100)
XGB_grid = GridSearchCV(XGB_grid,
                        param_grid, 
                        scoring = "recall", 
                        n_jobs=-1,
                        verbose=2).fit(X_train, y_train)

# Evaluate model after grid search
y_pred = XGB_grid.best_estimator_.predict(X_test)
evaluate(y_test, y_pred)

# Save each score for later comparison
xgb_grid_acc = accuracy_score(y_test, y_pred)
xgb_grid_recall = recall_score(y_test, y_pred)

"""### Feature Importance for XGBoost Model"""

XGB_grid.best_estimator_.feature_importances_

XGB_feature_imp = pd.DataFrame(index=X.columns, data=XGB_grid.best_estimator_.feature_importances_, columns=["Feature Importance"])
XGB_feature_imp = XGB_feature_imp.sort_values("Feature Importance")

XGB_feature_imp

# Plot feature importances
sns.barplot(x=XGB_feature_imp["Feature Importance"], y=XGB_feature_imp.index)
plt.title("Feature Importance")
plt.show()

"""Compare important features with other models"""

# Random Forest
sns.barplot(x=RF_feature_imp["Feature Importance"], y=RF_feature_imp.index)
plt.title("Feature Importance")
plt.show()

# Decision Tree
sns.barplot(x=DT_feature_imp["Feature Importance"], y=DT_feature_imp.index)
plt.title("Feature Importance")
plt.show()

"""## Comparing All Model"""

# Create df for model comparison
compare = pd.DataFrame({'Model': ["Decision Tree", "Random Forest", "XGBoost"],
                        'Recall': [dt_grid_recall, rf_grid_recall, xgb_grid_recall],
                        'Accuracy': [dt_grid_acc, rf_grid_acc, xgb_grid_acc],
                        })

# Def function to set label
def labels(ax):
    for p in ax.patches:
        width = p.get_width()                        # get bar length
        ax.text(width,                               # set the text at 1 unit right of the bar
                p.get_y() + p.get_height() / 2,      # get Y coordinate + X coordinate / 2
                '{:1.3f}'.format(width),             # set variable to display, 2 decimals
                ha = 'left',                         # horizontal alignment
                va = 'center')                       # vertical alignment

# Plot model comparison    
plt.figure(figsize=(15,15))
plt.subplot(411)
compare = compare.sort_values(by="Recall", ascending=False)
ax=sns.barplot(x="Recall", y="Model", data=compare, palette="Blues_d")
labels(ax)

plt.subplot(412)
compare = compare.sort_values(by="Accuracy", ascending=False)
ax=sns.barplot(x="Accuracy", y="Model", data=compare, palette="Blues_d")
labels(ax)

plt.show()

"""## Conclusion
Based on the 3 tree models that we have created, it seems that decision tree models fits best on this classification case with an average accuracy of 89% beating the other 2 models.
"""